期望是7，但大模型研究一年，公司资源和业务比较受限，可能还达不到。比较杂，代码、文本、
## 1.AI报表

背景通过对话的方式，生成债券报表，并对表格进行编辑和可视化操作。
**第一步**先做query改写，三个作用，第一个是去除干扰信息，用户有时候说的会比较啰嗦；第二是将时间表述标准化，第三是抽取出机构、指标、债券类型、地区等实体，用于后续步骤。
**第二步**生成表格，主要是用text2sql的思想，通过上一步得到的实体先去定位数据库中的表，将数据表的结构信息拼到prompt中，模型生成sql代码（时间范围内的数据，多表联合），执行得到报表。
**第三步**就是对上一步的结果进行编辑操作，包括筛选、排序、列管理、绘图分析，看上去感觉很简单，有点鸡肋，但用户一般会问的比较模糊：查看江浙沪的数据、我要近三周的债券，这种通过语言指令要比手动操作方便很多，另外比如帮我计算一下披露价格和实际价格的差距最大的10只债券，设计复杂操作。我们这里是借助llm的function call能力加上chain of command few-shot来实现用户意图的理解和指令生成的。
**评价指标**：定位成功率90%（指标解析不准，问的是股票）；表格操作成功率70%（字段选择错误，工具不支持）；绘图成功率65%（日期解析，数据缺失，图表推荐）
7B改写，13B指令
改写（指标、机构、行业、地区、时间）
=>定位表格一共20个（query|表名向量匹配；关键词匹配表描述；机构指标锁定）
=>表格操作（筛选、排序、列管理、统计分析、绘图指令）
=>可视化绘图（数据格式、缺失，日期解析）
迭代：用户说的太抽象了，需要兜底策略，键盘精灵指标推荐、问句推荐
**Llama：**RMS均方根，swiglu，rope，GQA，sft（2w高质量），reward（有用性，安全性）

## 2.写作
*！！首token延迟优化*
背景使希望能用ai写出专业研报，于是我们采用agent的方式进行任务拆解，分布进行。
**第一步**输入话题生成标题，分为三类：行业研报、公司研报和宏观研报，比如输入新能源输出新能源行业深度研究报告；
**第二步**根据标题和研报类别生成大纲，也就是整个研报的框架，比如一级标题1.新能源行业概述1.1新能源定义1.2发展历程2.产业链分析3.行业政策...层级只到二级标题，然后一般给到6~8个一级标题。
**第三步**生成规划，写作思路，是按每个子标题就是二级标题来生成的。思路的形式就是“先写什么在写什么分析一下总结一下啊”
**第四步**就开始走检索流程了，写专业内容就要有数据和专业知识做参考，我们把这些需要检索的统称为写作素材。但这里不是直接用上一步的思路里的文本去检索，而是先做了query扩展，将思路中每一块扩展成搜索query和指标query，这样形式上就与对应知识库对其了。比如“简述新能源的定义与类别”这一思路会扩展成“新能源销量”指标query和搜索query“新能源的概念，新能源的类别。
**第五步**就分别去对应的知识库检索，得到写作素材。指标库由100w个宏观指标组成，搜索库包含新闻、观点库、百度搜索引擎。检索指标是bge-base粗排top10+reranker精排top1的指标词，再通过规则分析器对指标进行扩展得到指标数值素材，比如新能源销量当月值，会扩展成季度值、年值、同比环比值，都是在写研报的时候会用到的；搜索库top10，新闻库用摘要做chunk（512），观点用观点句做chunk（64）。
**第六步**素材过滤，主要是从质量（语言流畅、敏感信息）、时效性和相关性三个角度进行打分，分别要使用三个模型，一个模型很难从三个角度都评价的比较准确。
**第七步**就是生成正文。为了体验专业性，会在做一步润色，其实就是在每节的开头有个总起句，比如新能源就是”新能源引领环保新潮流“，还有就是语言规范，删除“根据素材，根据你的要求”。

检索用召回率（指标）和上下文相关性（素材文本）
https://blog.csdn.net/m0_46850835/article/details/136377919
**评估方案**：检索用召回率（指标）和上下文相关性（素材文本），生成用rouge-1，rouge-分词，rouge-keyword；上线还是人工标注，主要从相关性（与思路一致）、准确性（与素材一致）、抗噪声能力、信息综合能力、拒绝无效回答能力

**可能存在的问题**：不同标题下的内容不连贯，我们是通过思路中加上”通过之前对新能源概念的描述，分析一下与传统车的区别“，这时候我们可以从记忆模块中取出新能源概念对应的素材和正文生成结果，当作当前素材。当然最好还是能多个小节或整篇文章一起生成，这也是我们现在优化的方向。
生成标题（fewshot，话题->标题）=>大纲（fewshot，1.行业概述1.1定义1.2发展历程2.产业链分析3.行业政策...10）
=>规划（400train，子标题 -> 简述新能源的定义；详细阐述类型，区别；分析优势、影响；总结）
=>query扩展（搜索/指标，指标实体+指标变量：系能源销量、燃油车销量；搜索对象+搜索内容：新能源定义、系能源类型）
=>指标召回（4.5w宏观指标，400个行业，bge top5->rerank top1）
=>素材搜索（指标库（同比环比均值高点）、新闻库、观点库、百度，bge）
=>素材过滤（3000train，质量、时效性、相关性打分，三个model）
=>生成正文（100train，8k->1k）
**RAG优点**:动态知识更新、领域知识库、可解释性、可溯源、减少模型幻觉


对于行业相关内容，从招股说明书和评级报告提取，包括行业简介、行业竞争趋势、行业壁垒、行业技术水平、行业周期性、季节性、区域性这几个小章节。每家机构的格式都不一样，构建了文档RAG方案，简单说先根据各级标题构建树形索引，召回相关内容，利用chatglm3做内容总结
用树型索引的原因在于：
- 报告本身就是一种树型结构
- 便于操作，比如一个节点匹配中了，可以直接根据禁用词裁剪不需要的叶子节点
- 便于重建文本


##### 3.客服
有非常多的功能页6w，用户主要会问功能页的路径或者当前功能页的操作说明。知识库最初只有路径类文本，语义太少了，只能用于字符匹配召回；于是我们通过数据增强构造QA对，从而构建了与用户问句对齐的文本向量库用于向量匹配。
多模态：用户输入包含图片，构建图片向量库（**visualized BGE**），召回的是图片对应的功能页路径
clip训图片文本对，检索图片emb|图片文本emb，图片emb效果更好。
召回85%，回答准确率75%。向量库支持动态更新。

##### 4.研报观点
背景，帮助提取研报核心内容，也是用在了研报写作任务中。
主要采用关键词检索，期货关键词包括黄金、铜、原油，宏观包括gdp、pmi、cpi（研报中表达方式比较多变，需要做关键词扩充，也是基于规则将其拓展为多个关键词），总结核心观点和论据。
朴素RAG，研报内容比较规整，表达明确，准确率较高85%以上



### RLHF DPO
RLHF包含四个模型，policy是要得到的目标模型，reference是参考模型，防止模型训歪，reward是打分模型，critic是收益模型。RLHF的目标函数由奖励r和KL散度正则项组成。奖励是优势函数，表现为实际奖励与预估奖励的差值。
DPO通过公式转化，将policy的参数由奖励r来表示，于是就考虑将奖励函数参数化到policy中，这样就只需要policy和reference两个参数。目标函数变为生成好的结果与生成差的结果的概率之差，通过构造prompt、好答案、差答案这种结构的训练数据即可dpo训练。


##### 5.事件抽取
从研报中抽取金融事件和对应的角色，比如(公司上市，公司名，上市时间，上市板块）
8类时间，准确率75%
GlobalPoint：传统是两个模块识别实体首尾，gp视为整体（上三角，n(n+1)/2个片段选k个实体）
![image-20240527195210810](file://C:/Users/viruser.v-desktop/AppData/Roaming/Typora/typora-user-images/image-20240527195210810.png?lastModify=1717642824)
RoPE相对位置、多标签分类交叉熵（softmax推广至多标签）、efficientGP（抽取共享、分类）

##### 6.热点新闻
主要思想是利用不同的数据增强方法生成正对，以两个独立的样本作为负对，然后采用InfoNCE损失拉进正对的嵌入，疏远负对的嵌入
现有构造方法的问题：
- 长度敏感：simcse中通过dropout构造的正对都是长度一样的，会让模型认为长度一样的才更相似
- 相似度边界：“上证指数今天跌幅扩大至2%”和“深证指数今天跌幅扩大至2%”
- 数据增强：词语删除、替换和重复等操作，缺乏导向性、无法控制样本的正负极性，且多样性不足。
方案：根据业务场景定义边界，构造提示模板；借助LLM生成正负样本；训练得到文本语义模型。
边界：不同行业的公司，发生相同事件时，属于不相似事件
模板：将下面句子中的公司实体换成同一行业的其他公司，并换一种表述方法（正样本）
​           将下面句子中的公司实体换成不同行业的其他公司，并换一种表述方法（负样本）
训练：增强数据混合通用数据，RoBERTa
​           InfoNCE损失（温度系数的作用就是控制**模型对负样本的区分度**）：
![image-20240528200842595](file://C:/Users/viruser.v-desktop/AppData/Roaming/Typora/typora-user-images/image-20240528200842595.png?lastModify=1717642824)
软负样本：双向边际损失，控制相似度差异在![image-20240528201739671](file://C:/Users/viruser.v-desktop/AppData/Roaming/Typora/typora-user-images/image-20240528201739671.png?lastModify=1717642824)区间内：
![image-20240528201250075](file://C:/Users/viruser.v-desktop/AppData/Roaming/Typora/typora-user-images/image-20240528201250075.png?lastModify=1717642824)
deta表示原始样本与正样本以及原始样本和负样本之间的差异，
![image-20240528201604423](file://C:/Users/viruser.v-desktop/AppData/Roaming/Typora/typora-user-images/image-20240528201604423.png?lastModify=1717642824)

7.智能助手
问答、闲聊、任务式
##### 8.recommend sys
##### **召回：**
GES：item冷启动方法，side information包括应用类型相关的属性。n个side 向量 + 1个item向量
EGES：对着n+1个向量进行加权；流程：在根据用户行为构建的item graph中随机游走，skipgram（根据当前word预测上下文）学习n+1个向量
##### **排序：**
**wide&deep**:wide用于记忆（线性部分），deep用于泛化MLP深度部分，wide采用原始特征+组合特征（and）
**DeepFM**:FM算法处理一阶特征和二阶特征,不需要人工特征工程
**LLM**：
query改写冷启动、可解释性推荐、rerank、用户反馈生成用户画像

9.数据接口助手

